# â­ GPU-Accelerated Image Convolution Using CUDA and Python

This project implements high-performance 2D image convolution using three backends:
1. **CPU (C implementation)**
2. **CUDA GPU executable**
3. **Python-callable CUDA shared library (`.so`)**

The goal is to compare performance across CPU, raw CUDA, and Python+CUDA, and demonstrate the speedups achieved through GPU acceleration.

## ğŸš€ Features
- Custom CUDA kernels for 2D convolution  
- Shared library (`libconv.so`) callable from Python using `ctypes`  
- CPU baseline implementation for comparison  
- Benchmarks on multiple images and filters (3Ã—3, 5Ã—5, 7Ã—7)  
- End-to-end pipeline for loading images, running convolution, and saving outputs  

## ğŸ–¥ï¸ Environment
This project was developed and executed entirely on **Google Colab** using the **NVIDIA T4 GPU** runtime.

Images were uploaded from the projectâ€™s `data/` folder directly into the Colab session using:
- Colabâ€™s file upload tool  
- Or by mounting Google Drive  

## ğŸ“Œ How to Run
1. Open the notebook in Google Colab  
2. Enable GPU:  
   **Runtime â†’ Change runtime type â†’ GPU (T4)**  
3. Upload images from your `data/` folder into the Colab environment  
4. Compile the CUDA code and build the shared library  
5. Run the Python wrapper to execute GPU convolution  

## ğŸ“¤ Output
- Convolved images saved in the notebook environment  
- Timing results for CPU, CUDA, and Python+CUDA  
- Demonstrated speedups of **50Ã—â€“170Ã—** depending on image and filter size  

## ğŸ“ Project Structure
