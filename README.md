# ‚ö° GPU-Accelerated Image Convolution Using CUDA and Python

This project implements high-performance 2D image convolution using three backends:
1. **CPU (C implementation)**
2. **CUDA GPU executable**
3. **Python-callable CUDA shared library (`.so`)**

The goal is to compare performance across CPU, raw CUDA, and Python+CUDA, and demonstrate the speedups achieved through GPU acceleration.

## üöÄ Features
- Custom CUDA kernels for 2D convolution  
- Shared library (`libconv.so`) callable from Python using `ctypes`  
- CPU baseline implementation for comparison  
- Benchmarks on multiple images and filters (3√ó3, 5√ó5, 7√ó7)  
- End-to-end pipeline for loading images, running convolution, and saving outputs  

## üñ•Ô∏è Environment
This project was developed and executed entirely on **Google Colab** using the **NVIDIA T4 GPU** runtime.

Images were uploaded from the project‚Äôs `data/` folder directly into the Colab session using:
- Colab‚Äôs file upload tool  
- Or by mounting Google Drive  

## üìå How to Run
1. Open the notebook in Google Colab  
2. Enable GPU:  
   **Runtime ‚Üí Change runtime type ‚Üí GPU (T4)**  
3. Upload images from your `data/` folder into the Colab environment  
4. Compile the CUDA code and build the shared library  
5. Run the Python wrapper to execute GPU convolution  

## üì§ Output
- Convolved images saved in the notebook environment  
- Timing results for CPU, CUDA, and Python+CUDA  
- Demonstrated speedups of **50√ó‚Äì170√ó** depending on image and filter size

